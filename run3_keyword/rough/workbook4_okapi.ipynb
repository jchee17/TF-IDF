{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "import pickle\n",
      "\n",
      "arxiv_sep_byfile = pickle.load(open('../clean/test_data_objects/arxiv_sep_byfile.p', 'r'))\n",
      "arxiv_sep_byword = pickle.load(open('../clean/test_data_objects/arxiv_sep_byword.p', 'r'))\n",
      "arxiv_wordsindoc = pickle.load(open('../clean/test_data_objects/arxiv_wordsindoc.p', 'r'))\n",
      "\n",
      "tfidf_arxiv = pickle.load(open('../clean/test_data_objects/tfidf_arxiv.p', 'r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute average doc length\n",
      "avg_dl = 0\n",
      "for f, val in arxiv_wordsindoc.iteritems():\n",
      "    avg_dl += val\n",
      "avg_dl /= len(arxiv_wordsindoc.keys())\n",
      "\n",
      "def okapi_bm25(word, doc,\n",
      "               k1, b, avg_dl, \n",
      "               corpus_byfile, corpus_byword, corpus_wordsindoc):\n",
      "    doc_term_count = corpus_byfile[doc][word]\n",
      "    doc_len = corpus_wordsindoc[doc]\n",
      "    doc_count = corpus_byword[word]\n",
      "    num_docs = len(corpus_byfile.keys())\n",
      "    \n",
      "    TF = ((k1 + 1.0) * doc_term_count) / ((k1 * ((1.0 - b) + b * doc_len / avg_dl)) \n",
      "                                          + doc_term_count)\n",
      "        \n",
      "    IDF = math.log(\n",
      "        1.0 + (num_docs - doc_count + 0.5) / (doc_count + 0.5))\n",
      "\n",
      " \n",
      "    return TF * IDF\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "okapi_arxiv = {}\n",
      "k1 = 1.2\n",
      "b = 0.75\n",
      "score = 0\n",
      "\n",
      "for f in arxiv_sep_byfile:\n",
      "    # initialize dictoinary\n",
      "    okapi_arxiv[f] = {}\n",
      "    \n",
      "    for keyword in arxiv_sep_byfile[f]:\n",
      "        score = okapi_bm25(keyword, f,\n",
      "                           k1, b, avg_dl,\n",
      "                           arxiv_sep_byfile, arxiv_sep_byword, arxiv_wordsindoc)\n",
      "        \n",
      "        # only keep score if meaningful\n",
      "        if (score > 0):\n",
      "            okapi_arxiv[f][keyword] = score\n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "okapi_test = pickle.load(open('../clean/test_data_objects/okapi_arxiv.p', 'r'))\n",
      "okapi_test == okapi_arxiv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "diff = 0\n",
      "count = 0\n",
      "for f in okapi_arxiv:\n",
      "    for keyword in okapi_arxiv[f]:\n",
      "        diff += abs(okapi_arxiv[f][keyword] - okapi_test[f][keyword])\n",
      "        count += 1\n",
      "\n",
      "print(diff / count)\n",
      "print(count)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000160391542513\n",
        "69837\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pickle.dump(okapi_arxiv, open('./data_objects/okapi_arxiv.p', 'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles = arxiv_sep_byfile.keys()\n",
      "sorted(okapi_arxiv[articles[0]].items(), key=lambda x : x[1], reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "[(u'kernel methods', 6.150945860588546),\n",
        " (u'smoothing', 5.5790205074540005),\n",
        " (u'confidence region', 4.11243969706949),\n",
        " (u'frequency', 3.8512725062595616),\n",
        " (u'confidence interval', 2.7585932671648146),\n",
        " (u'quantile', 2.6963314409911883),\n",
        " (u'stochastic', 2.2010107881647496),\n",
        " (u'event', 2.04585813527886),\n",
        " (u'empirical', 1.9608551452389673),\n",
        " (u'f-statistics', 1.5024645129804384),\n",
        " (u'estimator', 1.3114019419810403),\n",
        " (u'inference', 1.1574014835117954),\n",
        " (u'mean', 0.8915974278822819),\n",
        " (u'statistics', 0.8233284706067141),\n",
        " (u'probability', 0.6258376169631563),\n",
        " (u'statistica', 0.5789187608972542),\n",
        " (u'statistic', 0.3642265941629275)]"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted(okapi_test[articles[0]].items(), key=lambda x : x[1], reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "[(u'kernel methods', 6.151256559652379),\n",
        " (u'smoothing', 5.5790672514968955),\n",
        " (u'confidence region', 4.112742641380431),\n",
        " (u'frequency', 3.8514205220713826),\n",
        " (u'confidence interval', 2.7587964799042215),\n",
        " (u'quantile', 2.6965300671913592),\n",
        " (u'stochastic', 2.201095379529839),\n",
        " (u'event', 2.046008844135094),\n",
        " (u'empirical', 1.9609305067112377),\n",
        " (u'f-statistics', 1.5025751925551256),\n",
        " (u'estimator', 1.3114277021185503),\n",
        " (u'inference', 1.1574867438975356),\n",
        " (u'mean', 0.8916250815633073),\n",
        " (u'statistics', 0.8233700589072522),\n",
        " (u'probability', 0.6258837195104513),\n",
        " (u'statistica', 0.5789614071505808),\n",
        " (u'statistic', 0.3642405924699635)]"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted(tfidf_arxiv[articles[0]].items(), key=lambda x : x[1], reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "[(u'smoothing', 0.047648737872725895),\n",
        " (u'kernel methods', 0.00869816324651132),\n",
        " (u'frequency', 0.007171651757461928),\n",
        " (u'estimator', 0.004777714441256128),\n",
        " (u'stochastic', 0.004099288570017641),\n",
        " (u'confidence region', 0.003990322535656122),\n",
        " (u'empirical', 0.003651972832405996),\n",
        " (u'confidence interval', 0.0026798348690085546),\n",
        " (u'quantile', 0.002619421992433874),\n",
        " (u'mean', 0.002056884214791472),\n",
        " (u'event', 0.001987894744042039),\n",
        " (u'f-statistics', 0.001459979693687516),\n",
        " (u'statistics', 0.001166396148526505),\n",
        " (u'inference', 0.0011246478932796832),\n",
        " (u'statistic', 0.0006774408029691061),\n",
        " (u'probability', 0.0006079818044486832),\n",
        " (u'statistica', 0.000562373945983102)]"
       ]
      }
     ],
     "prompt_number": 33
    }
   ],
   "metadata": {}
  }
 ]
}