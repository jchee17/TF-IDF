{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division, unicode_literals\n",
      "\n",
      "import os\n",
      "import random\n",
      "import pickle\n",
      "import string\n",
      "import nltk\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import math\n",
      "from textblob import TextBlob\n",
      "\n",
      "path_arxiv = '/home/jerry/Data/Hopper_Project/ptm_data/arxiv_processed_trunc/'\n",
      "path_wiki = '/home/jerry/Data/Hopper_Project/ptm_data/wiki/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# alternate tfidf scores for dictionaries\n",
      "\n",
      "def tf(word, blob):\n",
      "    return blob.words.count(word) / len(blob.words)\n",
      "\n",
      "def n_containing_dict(word, bloblist):\n",
      "    return sum(1 for blob in bloblist if word in bloblist[blob]) # bc dictionary\n",
      "\n",
      "def idf_dict(word, bloblist):\n",
      "    return math.log(len(bloblist) / (1 + n_containing_dict(word, bloblist)))\n",
      "\n",
      "def tfidf_dict(word, blob, bloblist):\n",
      "    return tf(word, blob) * idf_dict(word, bloblist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load the document comparisons\n",
      "doc_comparisons = pickle.load(open('./doc_comparisons.p', 'r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# function to take in a arxiv paper name and output the top k wiki concepts\n",
      "\n",
      "def relevant_concepts(arxiv_doc, doc_comparisons, k):\n",
      "    print(\"\\nTop words in document: {}\".format(arxiv_doc))\n",
      "    \n",
      "    # check if arxiv_doc in doc_comparsions\n",
      "    if arxiv_doc in doc_comparisons.keys(): \n",
      "        scores = doc_comparisons[arxiv_doc]\n",
      "        sorted_words = sorted(scores.items(), key=lambda x : x[1], reverse = True)\n",
      "        for concept, score in sorted_words[:k]:\n",
      "            print(\"\\tConcept: {}, TF-IDF: {}\".format(concept, round(score, 5)))\n",
      "    \n",
      "    else:\n",
      "        print(\"\\tError: input doc not in doc_comparisons\")\n",
      "        \n",
      "def show_doc_text(arxiv_doc):\n",
      "    f = open('/home/jerry/Data/Hopper_Project/ptm_data/arxiv_processed_trunc/' + arxiv_doc, 'r')\n",
      "    text = f.read()\n",
      "    f.close()\n",
      "    print('\\n' + 'Title: ' + arxiv_doc + '\\n\\n' + text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles = doc_comparisons.keys()\n",
      "indices = list(xrange(len(articles)))\n",
      "\n",
      "while(1):\n",
      "    i = raw_input(\"There are 596 analyzed arxiv articles. Enter an integer from 0 to {} to access one of these articles.\\n\".format(len(articles)-1))\n",
      "    i = int(i)\n",
      "    if i not in indices:\n",
      "        print(\"Input not in range. Please try again.\\n\")\n",
      "    else:\n",
      "        relevant_concepts(articles[i], doc_comparisons, 5)\n",
      "        show_doc_text(articles[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "There are 596 analyzed arxiv articles. Enter an integer from 0 to 595 to access one of these articles.\n",
        "0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Top words in document: 1103.5679_trunc.txt\n",
        "\tConcept: consistent_estimator.txt, TF-IDF: 0.19094\n",
        "\tConcept: convergence_of_random_variables.txt, TF-IDF: 0.17523\n",
        "\tConcept: consistency_(statistics).txt, TF-IDF: 0.16065\n",
        "\tConcept: asymptotic_theory_(statistics).txt, TF-IDF: 0.16033\n",
        "\tConcept: fisher_consistency.txt, TF-IDF: 0.14355\n",
        "\n",
        "Title: 1103.5679_trunc.txt\n",
        "\n",
        "   Weak consistency of Markov chain Monte Carlo methods   Kengo KAMATANI Graduate School of Engineering Science, Osaka University Machikaneyama-cho 1-3, Toyonaka-si, Osaka, 560-0043, Japan, kamatani@sigmath.es.osaka-u.ac.jp Supported in part by Grant-in-Aid for JSPS Fellows (19-3140) and  Grant-in-Aid for Young Scientists (B) 22740055.        abstract  Markov chain Monte Calro methods (MCMC) are commonly used in Bayesian statistics. In the last twenty years, many results have been established for the calculation of the exact convergence rate of MCMC methods. We introduce  another  rate of convergence for MCMC methods by approximation techniques. This rate can be obtained by the convergence of the Markov chain to a diffusion process. We apply it to a  simple mixture model and obtain its convergence rate. Numerical simulations are performed to illustrate the effect of the rate.    Keyword: Markov chain Monte Carlo; Asymptotic Normality; Diffusion process abstract  Introduction Markov chain Monte Carlo (MCMC) method has become an essential tool in any study that has a complicated posterior calculation problem. Various new MCMC methods have been developed in the last two decades. Theoretical support of this strategy has also been developed such as RT, MT2 and many others. In particular, it was shown that the usual MCMC method produces an ergodic Markov chain (see TierneyAOS94 and RR).  In practice, it is of great interest to study the convergence speed of these Markov chains. Various  quantitative bounds have been developed from the spectral approach by such as MR1097463 and  DKS, and from the so-called (double) drift condition approach by MT1994 and R, ECP1054. For an ergodic  Markov chain  on the state space  with the  transition kernel , they calculated the upper bound of equationtv L(X_m)-=2_AEP(X_mA)-(A) equation where  is the invariant distribution and  is the law of . In the former approach, if we can calculate the eigenvalues and the eigenfunctions for , then it is possible to calculate the almost exact bounds. On the other hand, although the latter approach does not provide tight bound, it is relatively easy to apply.  To compare different MCMC methods, the above approaches may have difficulties, since we need to calculate  tight (upper and lower) bounds for two or more MCMC methods. However, without calculating such bounds, sometimes it is possible to compare different MCMC methods  by the asymptotic variance  in the following limit in : equation M(I_M-I)N(0,^2_f), I_M=1M_m=0^M-1f(X_m), I=_E f(x)(dx). equation For this comparison, it is sufficient to show positivity of an operator in  sense. This approach was studied in PESKUN01121973, and later developed by zbMATH01319841 and mira1998ordering. Although the application area of this is limited, this approach is particularly useful for the comparison of the so-called data-augmentation (DA) procedure with its parameter-expanded extension (see HobertMarchev08).  These analysis  on MCMC procedures obtain the exact bound of the convergence rate or the exact comparison of MCMC procedures. We took a different approach in  Kamatani10. Usually, MCMC procedures are complicated that prevent us from exact analysis. On the other hand, by using approximation theory, such as the  traditional large sample theory, sometimes it is easy to perform theoretical comparison among MCMC procedures. For this approximation, we introduce an index , which tends to . As ,  if the following holds for any , the MCMC procedure is said to have the consistency in Kamatani10: equationlc I^n_M_n-I^n=o_P(1), I^n_M=1M_m=0^M-1f(X_m^n), I^n=_E f(x)_n(dx) equation where  are sequences of -invariant  Markov chains generated by MCMC procedures. By Theorem 1 of Kamatani10, under some regularity conditions, the DA procedure   satisfies this property. In practice,  if an MCMC procedure has the  consistency, it works fairly well. On the other hand, many popular MCMC methods do not satisfy this good convergence property but satisfy a bad property equationdc I^n_M-I^n_1=o_P_n(1) equation for any fixed . This property means that the Monte Carlo estimation using  iteration is no more helpful than that using only one iteration. Therefore we can classify MCMC procedure into two categories (lc) or (dc). Although these two categories do not cover all of the cases, this classification is useful in practice. However it does not tell the rate of convergence.  In this paper, we introduce a further step of this approach. As mentioned earlier, the rate of convergence is useful to predict sufficient number of iteration until convergence, or to compare different MCMC procedures in details. We call  the order of the weak consistency if (lc) is satisfied for any such that . If the MCMC procedure has the  consistency, we can take . On the other hand, the order can be high if the performance of MCMC procedure is poor, that is, the condition (dc) is satisfied. The order  can be interpreted as the order of the sufficient number of iteration.   As an example we will consider the DA procedure for a simple mixture model  for unknown  but for known . Since the performance of the DA procedure heavily depends on the parameter , we let  to illustrate the effect. This DA procedure works quite poorly if the true model is close to . The index  is the sample size. It has the order  and this shows the effects of both  and the sample size . This result comes from the fact that the trajectory of the DA procedure tends to a path of the stochastic process defined by equationsde dX_t=(_1+X_t z-X_t^2 I)dt+2X_tdW_t equation where   corresponds to the Fisher information matrix and  corresponds to the scaled maximum likelihood estimator (see Theorem gibbsweak). It is probably well recognized that the trajectory of poor behaved MCMC procedure  looks like a path of a diffusion process. This result is the first validation for this observation.  This paper is organized as follows. Section Sec2 we define (local) weak consistency. In Section GSM we apply this to the simple mixture model. Numerical results is provided in Section NR which shows the effect of the order of the weak consistency.                        Local weak consistency of MCMCSec2 We write  for the integer part of .  Definition of local weak consistency  In this section, we review  the (local) consistency and degeneracy and also, we define the order of the weak consistency. Let\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-15-9a7742434372>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"There are 596 analyzed arxiv articles. Enter an integer from 0 to {} to access one of these articles.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/IPython/kernel/zmq/ipkernel.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;31m# raw_input in the user namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0mraw_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/IPython/kernel/zmq/ipkernel.pyc\u001b[0m in \u001b[0;36m_raw_input\u001b[0;34m(self, prompt, ident, parent)\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}