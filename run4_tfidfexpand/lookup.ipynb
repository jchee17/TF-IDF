{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I seem to have fixed my nan problem."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import unicode_literals\n",
      "from __future__ import division\n",
      "import os\n",
      "import re\n",
      "import pickle\n",
      "import numpy as np\n",
      "import webbrowser\n",
      "import nltk\n",
      "from nltk.corpus import stopwords\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cos_dist_tfidf = np.load(\"./data_objects/cos_dist_tfidf.npy\")\n",
      "cos_dist_okapi = np.load(\"./data_objects/cos_dist_okapi.npy\")\n",
      "\n",
      "tfidf_wiki = np.load(\"./data_objects/tfidf_wiki.npy\")\n",
      "tfidf_arxiv = np.load(\"./data_objects/tfidf_arxiv.npy\")\n",
      "\n",
      "okapi_bm25_wiki = np.load(\"./data_objects/okapi_bm25_wiki.npy\")\n",
      "okpapi_bm25_arxiv = np.load(\"./data_objects/okapi_bm25_arxiv.npy\")\n",
      "\n",
      "list_wiki = pickle.load(open(\"./data_objects/list_wiki.p\", 'r'))\n",
      "list_arxiv = pickle.load(open(\"./data_objects/list_arxiv.p\", 'r'))\n",
      "\n",
      "list_vocab = pickle.load(open('./data_objects/list_vocab.p', 'r'))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def lookup_top_n(cos_dist_array, list_articles, index, n):\n",
      "    \"\"\" given the index of article and cos_dist_array,\n",
      "        returns the index of top n concepts\n",
      "    \"\"\"\n",
      "    article_array = cos_dist_array[index]\n",
      "    \n",
      "    # give top n partition\n",
      "    sorted_ind = np.argpartition(article_array, -n)[-n:]\n",
      "    # sort in this top n\n",
      "    sorted_ind = sorted_ind[np.argsort(article_array[sorted_ind])[::-1]]\n",
      "    return sorted_ind\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def display_article(list_articles, index):\n",
      "    \"\"\" takes in article and displays arxiv.org/abs \n",
      "        page in browser\n",
      "    \"\"\"\n",
      "    # get id string\n",
      "    id_string = re.sub(\"\\_trunc.txt\", '', list_articles[index])\n",
      "    \n",
      "    # open in browser\n",
      "    webbrowser.open(\"http://arxiv.org/abs/\" + id_string)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "while (1):\n",
      "    i = raw_input(\"Integer from 0 to {}\\n\".format(len(list_arxiv)))\n",
      "    i = int(i)\n",
      "    \n",
      "    n = 10\n",
      "    top_n = lookup_top_n(cos_dist, list_arxiv, i, n)\n",
      "    \n",
      "    for j in range(n):\n",
      "        k = top_n[j]\n",
      "        print(list_wiki[k], cos_dist[i, k])\n",
      "        print('\\n')\n",
      "    \n",
      "    display_article(list_arxiv, i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Integer from 0 to 3631\n",
        "0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'statistical_dispersion.txt', 0.39534740857779871)\n",
        "\n",
        "\n",
        "(u'factorial_moment.txt', 0.38844755809900489)\n",
        "\n",
        "\n",
        "(u'tweedie_distribution.txt', 0.36323869827005839)\n",
        "\n",
        "\n",
        "(u'factorial_moment_generating_function.txt', 0.349090748605007)\n",
        "\n",
        "\n",
        "(u'coefficient_of_dispersion.txt', 0.34828598952995571)\n",
        "\n",
        "\n",
        "(u'variance-to-mean_ratio.txt', 0.34828598952995571)\n",
        "\n",
        "\n",
        "(u'index_of_dispersion.txt', 0.34828598952995571)\n",
        "\n",
        "\n",
        "(u'quartile_coefficient_of_dispersion.txt', 0.34372335280616784)\n",
        "\n",
        "\n",
        "(u'factorial_experiment.txt', 0.31861076117866627)\n",
        "\n",
        "\n",
        "(u'fully_crossed_design.txt', 0.31861076117866627)\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# stopword exploration. deemed not worth it now\n",
      "\n",
      "stops = set(stopwords.words('english'))\n",
      "stops_relevant = stops.intersection(list_vocab)\n",
      "print(len(stops_relevant), len(list_vocab))\n",
      "#list_vocab_rm = list_vocab.remove(stops_relevant)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(143, 21336)\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def top_contributions(score_articles, score_concepts, \n",
      "                      article_index, concept_index, \n",
      "                      list_common_vocab, n):\n",
      "    \"\"\" gives top n conributions to normalized dot product \"\"\"\n",
      "    article = score_articles[article_index,]\n",
      "    concept = score_concepts[concept_index,]\n",
      "    \n",
      "    # norms\n",
      "    norm_article = np.linalg.norm(article)\n",
      "    norm_concept = np.linalg.norm(concept)\n",
      "    norm = norm_article * norm_concept\n",
      "    \n",
      "    # store dot product separately in np array\n",
      "    len_vocab = len(list_common_vocab)\n",
      "    dot_product = map(lambda x: (article[x] * concept[x]) / (norm), range(len_vocab))\n",
      "    dot_product = np.array(dot_product)\n",
      "        \n",
      "    # give top n partition\n",
      "    sorted_ind = np.argpartition(dot_product, -n)[-n:]\n",
      "    \n",
      "    # sort in this top n\n",
      "    sorted_ind = sorted_ind[np.argsort(dot_product[sorted_ind])[::-1]]\n",
      "    \n",
      "    # format output\n",
      "    out = []\n",
      "    for i in range(n):\n",
      "        idx = sorted_ind[i]\n",
      "        out.append( (idx, list_common_vocab[idx], dot_product[idx]) )\n",
      "        \n",
      "    return (out)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_contributions(tfidf_arxiv, tfidf_wiki, \n",
      "                  2250, 1891, list_vocab, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[(7143, u'price', 0.082667684558391213),\n",
        " (7099, u'investors', 0.041157987430210687),\n",
        " (12849, u'market', 0.020220928913256324),\n",
        " (13928, u'prices', 0.012830532225295203),\n",
        " (18750, u'markets', 0.0049067419737899628)]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_contributions(okpapi_bm25_arxiv, okapi_bm25_wiki, \n",
      "                  2250, 1891, list_vocab, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "[(7099, u'investors', 0.016763555920372729),\n",
        " (7143, u'price', 0.0083312841407939073),\n",
        " (13928, u'prices', 0.0076540319471817457),\n",
        " (18750, u'markets', 0.0075647325208259199),\n",
        " (15466, u'traders', 0.0072896861065376208)]"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_wiki.index('cluster_analysis.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "2485"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cos_dist_tfidf[1750, 2485]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "0.11458642562980004"
       ]
      }
     ],
     "prompt_number": 7
    }
   ],
   "metadata": {}
  }
 ]
}