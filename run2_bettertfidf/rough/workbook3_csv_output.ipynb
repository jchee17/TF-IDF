{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import random\n",
      "import pickle\n",
      "import math\n",
      "import re\n",
      "import webbrowser\n",
      "\n",
      "# import tfidf_*_norm to recompute doc_comparisons with\n",
      "# wiki as key\n",
      "def dot_product(u,v):\n",
      "    return sum(u[i]*v[i] for i in range(len(u)))\n",
      "\n",
      "# load\n",
      "vocab = pickle.load(open('../data_objects/vocab.p', 'r'))\n",
      "tfidf_wiki = pickle.load(open('./data_objects/tfidf_wiki.p', 'r'))\n",
      "tfidf_wiki_norm = pickle.load(open('./data_objects/tfidf_wiki_norm.p', 'r'))\n",
      "tfidf_arxiv_norm = pickle.load(open('./data_objects/tfidf_arxiv_norm.p', 'r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# document comparisons by wiki\n",
      "doc_comparisons_bywiki = {}\n",
      "\n",
      "for f in tfidf_wiki_norm:\n",
      "    doc_comparisons_bywiki[f] = {key:dot_product(tfidf_wiki_norm[f], tfidf_arxiv_norm[key]) \n",
      "                            for key in tfidf_arxiv_norm}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pickle\n",
      "pickle.dump(doc_comparisons_bywiki, open('./data_objects/doc_comparisons_bywiki.p', 'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab_list = []\n",
      "for word in vocab:\n",
      "    vocab_list.append(word)\n",
      "vocab_list[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "u'writings'"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make tfidf_wiki a double dictionary\n",
      "tfidf_wiki_dict = {}\n",
      "vocab_list = []\n",
      "\n",
      "for word in vocab:\n",
      "    vocab_list.append(word)\n",
      "\n",
      "for f in tfidf_wiki:\n",
      "    tfidf_wiki_dict[f] = {}\n",
      "    for i in range(len(vocab_list)):\n",
      "        tfidf_wiki_dict[f][vocab_list[i]] = tfidf_wiki[f][i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(tfidf_wiki_dict, open('./data_objects/tfidf_wiki_dict.p', 'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's now output our 1st csv file\n",
      "#csv1_out = open('./data_objects/csv_top_wikiwords.csv', 'w')\n",
      "\n",
      "for f in tfidf_wiki_dict:\n",
      "    #csv1_out.write(f+',')\n",
      "    print(f)\n",
      "    scores = tfidf_wiki_dict[f]\n",
      "    sorted_words = sorted(scores.items(), key=lambda x : x[1], reverse = True)\n",
      "    \n",
      "    i = 0\n",
      "    for item in sorted_words:\n",
      "        if (i < 10):\n",
      "            #csv1_out.write(item[0]+',')\n",
      "            print(\"\\t\"+item[0])\n",
      "            \n",
      "            i += 1\n",
      "        else:\n",
      "            #csv1_out.write('\\n')\n",
      "            break\n",
      "    \n",
      "    #print(sorted_words[:10])\n",
      "    #print(\"break\")\n",
      "\n",
      "#scores = {word: tfidf(word, doc, doclist_wiki) for word in doc.words}\n",
      "    #sorted_words = sorted(scores.items(), key=lambda x : x[1], reverse = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "efficiency_(statistics).txt\n",
        "\tefficiency\n",
        "\testimator\n",
        "\teff\n",
        "\testimators\n",
        "\tefficient\n",
        "\tmr\n",
        "\trelative\n",
        "\tequality\n",
        "\tquality\n",
        "\tinefficient\n",
        "convergence_of_random_variables.txt\n",
        "\tconverge\n",
        "\tconvergence\n",
        "\tconverges\n",
        "\tsurely\n",
        "\tsequence\n",
        "\talmost\n",
        "\trely\n",
        "\tproof\n",
        "\timplies\n",
        "\tmost\n",
        "consistency_(statistics).txt\n",
        "\titems\n",
        "\titem\n",
        "\tincrease\n",
        "\tincreases\n",
        "\tconsistency\n",
        "\tconsistent\n",
        "\tconsist\n",
        "\tgrow\n",
        "\tproperty\n",
        "\tlimited\n",
        "analytic_and_enumerative_statistical_studies.txt\n",
        "\tenumerative\n",
        "\tanalytic\n",
        "\tdistinction\n",
        "\tfuture\n",
        "\tstudy\n",
        "\tstudies\n",
        "\tjudgment\n",
        "\tdistinct\n",
        "\tframe\n",
        "\tdie\n",
        "random_variable.txt\n",
        "\tvalued\n",
        "\trandom\n",
        "\tando\n",
        "\tvariable\n",
        "\tspace\n",
        "\tvariables\n",
        "\treal\n",
        "\tcumulative\n",
        "\tmass\n",
        "\tnumbers\n",
        "statistical_inference.txt\n",
        "\tinference\n",
        "\tinfer\n",
        "\tassumptions\n",
        "\trandomized\n",
        "\tassumption\n",
        "\tfrequentist\n",
        "\tparadigm\n",
        "\tdatasets\n",
        "\tbelief\n",
        "\trandomization\n",
        "design_of_experiments.txt\n",
        "\tdesign\n",
        "\texperiment\n",
        "\tdesigns\n",
        "\texperimental\n",
        "\texperiments\n",
        "\tday\n",
        "\tsign\n",
        "\ttreatments\n",
        "\tparticipant\n",
        "\tcontrol\n",
        "maximum_likelihood.txt\n",
        "\tlikelihood\n",
        "\tmax\n",
        "\tmaximum\n",
        "\tlike\n",
        "\testimator\n",
        "\tmaximize\n",
        "\txi\n",
        "\testimation\n",
        "\tdensity\n",
        "\tmatrix\n",
        "consistent_estimator.txt\n",
        "\tconsistent\n",
        "\tconverge\n",
        "\tconsist\n",
        "\tconsistency\n",
        "\testimator\n",
        "\tconverges\n",
        "\tsequence\n",
        "\tbiased\n",
        "\tbias\n",
        "\testimators\n",
        "parameter_space.txt\n",
        "\tspace\n",
        "\tplane\n",
        "\tgeometry\n",
        "\tdimensions\n",
        "\tfour\n",
        "\tspheres\n",
        "\tmens\n",
        "\tdimension\n",
        "\tplotted\n",
        "\tsphere\n",
        "entropy_(information_theory).txt\n",
        "\tentropy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tpy\n",
        "\tbits\n",
        "\tinformation\n",
        "\tinform\n",
        "\tformat\n",
        "\tbit\n",
        "\tsymbol\n",
        "\tsource\n",
        "\tcompression\n",
        "completeness_(statistics).txt\n",
        "\tcomplete\n",
        "\tcompleteness\n",
        "\tlet\n",
        "\tsufficient\n",
        "\ttheorem\n",
        "\texpectation\n",
        "\tbounded\n",
        "\timplication\n",
        "\toccurs\n",
        "\tparametric\n",
        "studentization.txt\n",
        "\tdividing\n",
        "\tcomplicates\n",
        "\tstandardised\n",
        "\tbootstrapping\n",
        "\tcomplication\n",
        "\tpseudonym\n",
        "\tdivision\n",
        "\tcube\n",
        "\tresampling\n",
        "\tbootstrap\n",
        "fisher_consistency.txt\n",
        "\tconsistency\n",
        "\tconsistent\n",
        "\tconsist\n",
        "\testimator\n",
        "\tanalogue\n",
        "\tshe\n",
        "\tpopulation\n",
        "\tdesirable\n",
        "\tempirical\n",
        "\tempiric\n",
        "pivotal_quantity.txt\n",
        "\tpivot\n",
        "\tpivotal\n",
        "\timproves\n",
        "\tpivots\n",
        "\tquantities\n",
        "\tnormal\n",
        "\tnorm\n",
        "\tcorrelation\n",
        "\tnor\n",
        "\tnormality\n",
        "window_function.txt\n",
        "\twindow\n",
        "\twindows\n",
        "\tcosine\n",
        "\trectangular\n",
        "\tangular\n",
        "\tsine\n",
        "\ttang\n",
        "\tspectral\n",
        "\tfrequency\n",
        "\twidth\n",
        "independent_and_identically_distributed_random_variables.txt\n",
        "\texchangeable\n",
        "\texchange\n",
        "\tidentically\n",
        "\tsequence\n",
        "\tloaded\n",
        "\tsignal\n",
        "\tunfair\n",
        "\thit\n",
        "\tvariables\n",
        "\tidentical\n",
        "frequency_(statistics).txt\n",
        "\tfrequency\n",
        "\tfrequentists\n",
        "\tfrequencies\n",
        "\tevent\n",
        "\tevents\n",
        "\tplotted\n",
        "\thistogram\n",
        "\tgram\n",
        "\tinterpretation\n",
        "\toccurrence\n",
        "galtons_problem.txt\n",
        "\tcorrelation\n",
        "\tcultural\n",
        "\tautocorrelation\n",
        "\tcross\n",
        "\tcorrelations\n",
        "\trelation\n",
        "\tsignificance\n",
        "\tross\n",
        "\tnth\n",
        "\tevolution\n",
        "fiducial_inference.txt\n",
        "\tfiducial\n",
        "\tinference\n",
        "\tuniquely\n",
        "\tstatement\n",
        "\tinterpretation\n",
        "\tinfer\n",
        "\tinterpret\n",
        "\tinterval\n",
        "\thad\n",
        "\tattempt\n",
        "statistical_manifold.txt\n",
        "\tmanifold\n",
        "\told\n",
        "\tsigma\n",
        "\tspace\n",
        "\tmanifolds\n",
        "\tcoordinate\n",
        "\tdimensional\n",
        "\tgeometry\n",
        "\tsmooth\n",
        "\tmoot\n",
        "winsorising.txt\n",
        "\tpercentile\n",
        "\ttrimming\n",
        "\t5th\n",
        "\ttrimmed\n",
        "\t90\n",
        "\trise\n",
        "\toutliers\n",
        "\toutlier\n",
        "\t95\n",
        "\tbottom\n",
        "bayesian_inference.txt\n",
        "\tevidence\n",
        "\tposterior\n",
        "\tprior\n",
        "\tyes\n",
        "\tbelief\n",
        "\tupdating\n",
        "\tinference\n",
        "\tupdate\n",
        "\trule\n",
        "\tinfer\n",
        "sufficient_statistic.txt\n",
        "\tfactorization\n",
        "\tsufficient\n",
        "\tjoint\n",
        "\tsufficiency\n",
        "\tfactor\n",
        "\ttheorem\n",
        "\tpdf\n",
        "\tdensity\n",
        "\tdf\n",
        "\tconditional\n",
        "efficient_estimator.txt\n",
        "\tefficiency\n",
        "\testimator\n",
        "\testimators\n",
        "\teff\n",
        "\tmr\n",
        "\tequality\n",
        "\tcriterion\n",
        "\tefficient\n",
        "\tinequality\n",
        "\tquality\n",
        "maximum_a_posteriori_estimation.txt\n",
        "\tposterior"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\toptimization\n",
        "\tprior\n",
        "\tsimulated\n",
        "\tconjugate\n",
        "\tderivatives\n",
        "\tmodal\n",
        "\trespective\n",
        "\tyes\n",
        "\testimate\n",
        "youdens_j_statistic.txt\n",
        "\tdiagnostic\n",
        "\tindex\n",
        "\tdichotomous\n",
        "\tdelta\n",
        "\thot\n",
        "\tspecificity\n",
        "\tsensitivity\n",
        "\tformed\n",
        "\tsingle\n",
        "\tperformance\n",
        "recursive_partitioning.txt\n",
        "\trecursive\n",
        "\tpartitioning\n",
        "\tpartition\n",
        "\tadvantages\n",
        "\tmultivariable\n",
        "\tdisadvantages\n",
        "\tcreate\n",
        "\toverfit\n",
        "\tcreates\n",
        "\tadvantage\n",
        "restricted_maximum_likelihood.txt\n",
        "\tmixed\n",
        "\tdirective\n",
        "\tcommand\n",
        "\t1937\n",
        "\tunbalanced\n",
        "\tlme4\n",
        "\tcomponent\n",
        "\testimation\n",
        "\tpackages\n",
        "\tbalanced\n",
        "kullback-leibler_divergence.txt\n",
        "\tdivergence\n",
        "\tdiverge\n",
        "\tentropy\n",
        "\tpy\n",
        "\tbits\n",
        "\tinformation\n",
        "\tformat\n",
        "\tinform\n",
        "\tgain\n",
        "\tbit\n",
        "exponential_dispersion_model.txt\n",
        "\tgeneralisation\n",
        "\tpersi\n",
        "\tdispersion\n",
        "\tnatural\n",
        "\tenables\n",
        "\texponential\n",
        "\tterminology\n",
        "\tscalar\n",
        "\texponent\n",
        "\tcanonical\n",
        "behrens-fisher_problem.txt\n",
        "\teh\n",
        "\tsolution\n",
        "\tvariances\n",
        "\tsolutions\n",
        "\tshe\n",
        "\tproblem\n",
        "\t197\n",
        "\t1975\n",
        "\t75\n",
        "\tproposed\n",
        "asymptotic_theory_(statistics).txt\n",
        "\tasymptotic\n",
        "\tym\n",
        "\tassumed\n",
        "\tsy\n",
        "\tframework\n",
        "\testimators\n",
        "\tframe\n",
        "\tgrow\n",
        "\tconverge\n",
        "\tasymptotics\n",
        "sensitivity_and_specificity.txt\n",
        "\tsensitivity\n",
        "\tspecificity\n",
        "\tcorrectly\n",
        "\thealthy\n",
        "\tnegative\n",
        "\tidentified\n",
        "\tpositive\n",
        "\tdisease\n",
        "\thealth\n",
        "\tpatient\n",
        "spatial_dependence.txt\n",
        "\tspatial\n",
        "\tinterpolation\n",
        "\tdependence\n",
        "\tlocations\n",
        "\tcorrelation\n",
        "\timportance\n",
        "\tgauge\n",
        "\tgeostatistics\n",
        "\tthemes\n",
        "\texhibits\n",
        "loss_function.txt\n",
        "\tloss\n",
        "\tdecision\n",
        "\tdec\n",
        "\trule\n",
        "\trisk\n",
        "\texpected\n",
        "\tfunction\n",
        "\texpect\n",
        "\tadr\n",
        "\teconomics\n",
        "statistical_parameter.txt\n",
        "\tindex\n",
        "\tregarded\n",
        "\tregard\n",
        "\tinferences\n",
        "\tfamily\n",
        "\tparameter\n",
        "\tmeter\n",
        "\tvoter\n",
        "\tvoters\n",
        "\tdestructively\n",
        "conditionality_principle.txt\n",
        "\tconditionality"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconditional\n",
        "\tprinciple\n",
        "\t1962\n",
        "\texperiments\n",
        "\txh\n",
        "\t196\n",
        "\tcondition\n",
        "\tmixture\n",
        "\tformally\n",
        "statistical_model.txt\n",
        "\tb0\n",
        "\tb1\n",
        "\tmodels\n",
        "\tadequately\n",
        "\t20\n",
        "\tadequate\n",
        "\t200\n",
        "\tmode\n",
        "\tmodel\n",
        "\tequate\n",
        "information_geometry.txt\n",
        "\tmanifold\n",
        "\tconnection\n",
        "\tdiverge\n",
        "\taffine\n",
        "\tdivergence\n",
        "\ttangent\n",
        "\tgeometry\n",
        "\ttang\n",
        "\tparallel\n",
        "\tcoordinate\n",
        "extreme_value_theory.txt\n",
        "\textreme\n",
        "\tevents\n",
        "\tevent\n",
        "\tflood\n",
        "\ttail\n",
        "\tyear\n",
        "\twave\n",
        "\tdisciplines\n",
        "\tanalyses\n",
        "\ttheory\n",
        "magnitude_of_completeness.txt\n",
        "\tearthquake\n",
        "\tearthquakes\n",
        "\tearth\n",
        "\tmagnitude\n",
        "\tinterpreting\n",
        "\tcatalog\n",
        "\tdetected\n",
        "\treliably\n",
        "\terroneous\n",
        "\twest\n",
        "response_surface_methodology.txt\n",
        "\tsurface\n",
        "\tmethodology\n",
        "\tdesign\n",
        "\tresponse\n",
        "\tdesigns\n",
        "\tsign\n",
        "\tbic\n",
        "\tcomposite\n",
        "\texplanatory\n",
        "\tmethod\n",
        "peirces_criterion.txt\n",
        "\toutlier\n",
        "\toutliers\n",
        "\tcriterion\n",
        "\tonline\n",
        "\ttables\n",
        "\tpeirce\n",
        "\tcode\n",
        "\ttp\n",
        "\tidentify\n",
        "\t85\n",
        "edgeworth_series.txt\n",
        "\texpansion\n",
        "\tworth\n",
        "\tpan\n",
        "\tcumulant\n",
        "\tcumulants\n",
        "\tseries\n",
        "\tdg\n",
        "\tdensity\n",
        "\texpansions\n",
        "\tguarantee\n",
        "decoupling_(probability).txt\n",
        "\tcouplings\n",
        "\tdecoupling\n",
        "\tdecomposition\n",
        "\tunrelated\n",
        "\tconditioned\n",
        "\tcomposition\n",
        "\treduction\n",
        "\tconfused\n",
        "\tconfuse\n",
        "\tevaluated\n",
        "statistic.txt\n",
        "\titems\n",
        "\titem\n",
        "\tarithmetic\n",
        "\tmeasure\n",
        "\tsure\n",
        "\tsingle\n",
        "\tpopulation\n",
        "\talgorithm\n",
        "\tdifferentiates\n",
        "\tcontemplate\n",
        "bias_of_an_estimator.txt\n",
        "\tbias\n",
        "\tbiased\n",
        "\testimator\n",
        "\tunbiased\n",
        "\tcorrected\n",
        "\tminimise\n",
        "\texpect\n",
        "\tuncorrected\n",
        "\tloss\n",
        "\tmedian\n",
        "a_priori_probability.txt\n",
        "\tpriori\n",
        "\tprobabilities\n",
        "\tprior\n",
        "\tevents\n",
        "\tdeductive\n",
        "\tdistinguishing\n",
        "\toccurring\n",
        "\treasoning\n",
        "\tindifference\n",
        "\texhaustive\n",
        "uncertainty.txt\n",
        "\tcertainty\n",
        "\tuncertain\n",
        "\tuncertainty\n",
        "\tcertain\n",
        "\tscientists\n",
        "\tscientific\n",
        "\tlists\n",
        "\tissue\n",
        "\tdown\n",
        "\tlosing\n",
        "ancillary_statistic.txt\n",
        "\tancillary\n",
        "\tcomplement\n",
        "\tbatting\n",
        "\tpersi\n",
        "\tdispersion\n",
        "\tconvey\n",
        "\tsufficient\n",
        "\tdoes\n",
        "\tdoe\n",
        "\tobserves\n",
        "errors_and_residuals.txt\n",
        "\tresidual\n",
        "\tresiduals\n",
        "\tobservable\n",
        "\tdual\n",
        "\tunobservable\n",
        "\terrors\n",
        "\terror\n",
        "\tstudentized\n",
        "\tstudent\n",
        "\tdeviation\n",
        "parametric_model.txt\n",
        "\tparametric\n",
        "\tmetric\n",
        "\tregular\n",
        "\tdimensional\n",
        "\tsemi\n",
        "\tparametrize\n",
        "\tmens\n",
        "\tdimension\n",
        "\tidentifiable\n",
        "\tfinite\n",
        "coherence_(statistics).txt\n",
        "\tcoherence\n",
        "\tpersonal\n",
        "\tperson\n",
        "\tcoherency\n",
        "\tgambling\n",
        "\tstrategy\n",
        "\tconsistency\n",
        "\texpressing\n",
        "\tassociation\n",
        "\tassessments\n",
        "likelihood-ratio_test.txt\n",
        "\tnull"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tlikelihood\n",
        "\treject\n",
        "\ttest\n",
        "\thypothesis\n",
        "\tratio\n",
        "\talternative\n",
        "\tthesis\n",
        "\tlike\n",
        "\tnested\n",
        "berkson_error_model.txt\n",
        "\tclassical\n",
        "\tclassic\n",
        "\tentitled\n",
        "\taggregated\n",
        "\tepidemiological\n",
        "\tattenuate\n",
        "\tmisclassification\n",
        "\texposure\n",
        "\taggregate\n",
        "\tregressions\n",
        "model_selection.txt\n",
        "\telection\n",
        "\tselection\n",
        "\t20\n",
        "\t200\n",
        "\tdoi\n",
        "\tcandidate\n",
        "\t36\n",
        "\tselect\n",
        "\tcriterion\n",
        "\t2008\n",
        "semiparametric_model.txt\n",
        "\tsemiparametric\n",
        "\tparametric\n",
        "\tsemi\n",
        "\tdimensional\n",
        "\tnonparametric\n",
        "\tmetric\n",
        "\thazard\n",
        "\tmens\n",
        "\tdimension\n",
        "\tinfinite\n",
        "mathematical_statistics.txt\n",
        "\tparametric\n",
        "\trandomized\n",
        "\tprint\n",
        "\texperiments\n",
        "\tsuccess\n",
        "\tinfer\n",
        "\tinferential\n",
        "\tdescriptive\n",
        "\tinference\n",
        "\t7\n",
        "principle_of_maximum_entropy.txt\n",
        "\tpy\n",
        "\tentropy\n",
        "\ttestable\n",
        "\tstable\n",
        "\tconstraint\n",
        "\tconstrain\n",
        "\train\n",
        "\tmax\n",
        "\tmaximum\n",
        "\tprinciple\n",
        "binomial_proportion_confidence_interval.txt\n",
        "\tinterval\n",
        "\tsuccesses\n",
        "\tbinomial\n",
        "\tquantile\n",
        "\tsuccess\n",
        "\tconfidence\n",
        "\tproportion\n",
        "\tportion\n",
        "\ttrial\n",
        "\ttrials\n",
        "statistical_assumption.txt\n",
        "\tassumptions\n",
        "\tassumption\n",
        "\t2006\n",
        "\t06\n",
        "\t1990\n",
        "\tij\n",
        "\t90\n",
        "\t1988\n",
        "\tsum\n",
        "\t200\n",
        "invariant_estimator.txt\n",
        "\tinvariant\n",
        "\tvariant\n",
        "\tinvariance\n",
        "\testimator\n",
        "\ttransformation\n",
        "\ttransitive\n",
        "\tgroup\n",
        "\ttransform\n",
        "\ttransformations\n",
        "\toup\n",
        "sampling_distribution.txt\n",
        "\tsampling\n",
        "\tjoint\n",
        "\tplacing\n",
        "\treplacing\n",
        "\tinference\n",
        "\tinfer\n",
        "\tspecifically\n",
        "\tapproximated\n",
        "\tpopulation\n",
        "\tasymptotic\n",
        "l-statistic.txt\n",
        "\tanalogs"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tnarrower\n",
        "\tnamely\n",
        "\tconventional\n",
        "\tarrow\n",
        "\tconvention\n",
        "\tmoments\n",
        "\tcombination\n",
        "\tmoment\n",
        "\tname\n",
        "bias_(statistics).txt\n",
        "\tbias\n",
        "\tarises\n",
        "\tarise\n",
        "\tpatient\n",
        "\trise\n",
        "\tstudy\n",
        "\tparticipant\n",
        "\tdue\n",
        "\tleading\n",
        "\tindividuals\n",
        "statistical_population.txt\n",
        "\tbp\n",
        "\tsubpopulation\n",
        "\tsubpopulations\n",
        "\tpeople\n",
        "\tpopulations\n",
        "\tsubset\n",
        "\tshare\n",
        "\tpopulation\n",
        "\tmodeled\n",
        "\tseparate\n",
        "robust_statistics.txt\n",
        "\toutlier\n",
        "\toutliers\n",
        "\tspeed\n",
        "\trobust\n",
        "\tbreakdown\n",
        "\tbreak\n",
        "\tinfluence\n",
        "\tdown\n",
        "\testimator\n",
        "\ttrimmed\n",
        "shrinkage_(statistics).txt\n",
        "\tshrinkage\n",
        "\tmeanings\n",
        "\teffects\n",
        "\teffect\n",
        "\tcomplementary\n",
        "\tmeaning\n",
        "\tregularize\n",
        "\timproving\n",
        "\twhereby\n",
        "\tdetermination\n",
        "fisher_transformation.txt\n",
        "\tbivariate\n",
        "\tcorrelation\n",
        "\ttransformation\n",
        "\tcoefficient\n",
        "\ttransform\n",
        "\tefficient\n",
        "\trelation\n",
        "\tpairs\n",
        "\tpair\n",
        "\tpai\n",
        "optimal_design.txt\n",
        "\toptimality\n",
        "\tdesigns\n",
        "\toptimal\n",
        "\tdesign\n",
        "\tsign\n",
        "\tcriterion\n",
        "\texperiment\n",
        "\texperimental\n",
        "\texperiments\n",
        "\texperimentation\n",
        "shrinkage_estimator.txt\n",
        "\tshrinkage\n",
        "\timplicit\n",
        "\teffect\n",
        "\timproved\n",
        "\ttoward\n",
        "\ttowards\n",
        "\tregular\n",
        "\tproved\n",
        "\testimator\n",
        "\teffects\n",
        "nuisance_parameter.txt\n",
        "\tnuisance\n",
        "\tpresence\n",
        "\tfrequentist\n",
        "\tanalysis\n",
        "\tparameters\n",
        "\tmeters\n",
        "\tinterest\n",
        "\taccount\n",
        "\tjoint\n",
        "\taccounted\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 2nd csv\n",
      "# convert doc_comparisons_bywiki to have 2nd dict be a list\n",
      "doc_comparisons_bywiki_2ndlist = {}\n",
      "\n",
      "for f in doc_comparisons_bywiki:\n",
      "    doc_comparisons_bywiki_2ndlist[f] = []\n",
      "    for key in doc_comparisons_bywiki[f]:\n",
      "        doc_comparisons_bywiki_2ndlist[f].append(doc_comparisons_bywiki[f][key])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now lets output 2nds csv\n",
      "csv2_out = open('./data_objects/csv_wikiarxiv_5numsum.csv', 'w')\n",
      "csv2_out.write(\"wiki_concept,min,1st quartile,meidan,3rd quartile,max,\\n\")\n",
      "\n",
      "for f in doc_comparisons_bywiki_2ndlist:\n",
      "    csv2_out.write(f+',')\n",
      "    tmp = np.array(doc_comparisons_bywiki_2ndlist[f])\n",
      "    \n",
      "    min = np.amin(tmp)\n",
      "    first_q = np.percentile(tmp, 25)\n",
      "    median = np.percentile(tmp, 50)\n",
      "    third_q = np.percentile(tmp, 75)\n",
      "    max = np.amax(tmp)\n",
      "    \n",
      "    csv2_out.write(\"{},{},{},{},{},\\n\".format(min, first_q, median, third_q, max))\n",
      "    \n",
      "    \n",
      "csv2_out.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    }
   ],
   "metadata": {}
  }
 ]
}