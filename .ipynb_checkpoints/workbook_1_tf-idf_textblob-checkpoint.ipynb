{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "http://stevenloria.com/finding-important-words-in-a-document-using-tf-idf/\n",
      "\n",
      "http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\n",
      "\n",
      "https://radimrehurek.com/gensim/tutorial.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division, unicode_literals\n",
      "\n",
      "import os\n",
      "import string\n",
      "import nltk\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import math\n",
      "from textblob import TextBlob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define functions for tfidf score\n",
      "\n",
      "def tf(word, blob):\n",
      "    return blob.words.count(word) / len(blob.words)\n",
      "\n",
      "def n_containing(word, bloblist):\n",
      "    return sum(1 for blob in bloblist if word in blob)\n",
      "\n",
      "def idf(word, bloblist):\n",
      "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
      "\n",
      "def tfidf(word, blob, bloblist):\n",
      "    return tf(word, blob) * idf(word, bloblist)\n",
      "\n",
      "def tfidf_diagnostic(word, blob, bloblist, df):\n",
      "    tf_val = tf(word,blob)\n",
      "    n_containing_val = n_containing(word, bloblist)\n",
      "    idf_val = idf(word, bloblist)\n",
      "    tfidf_val = tfidf(word, blob, bloblist)\n",
      "    \n",
      "    df.append({'tfidf':tfidf_val, 'tf':tf_val, 'idf':idf_val, 'n_containing':n_containing_val})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# alternate tfidf scores for dictionaries\n",
      "\n",
      "def n_containing_dict(word, bloblist):\n",
      "    return sum(1 for blob in bloblist if word in bloblist[blob]) # bc dictionary\n",
      "\n",
      "def idf_dict(word, bloblist):\n",
      "    return math.log(len(bloblist) / (1 + n_containing_dict(word, bloblist)))\n",
      "\n",
      "def tfidf_dict(word, blob, bloblist):\n",
      "    return tf(word, blob) * idf_dict(word, bloblist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_arxiv = '/home/jerry/Data/Hopper_Project/ptm_data/arxiv_processed_trunc/'\n",
      "path_wiki = '/home/jerry/Data/Hopper_Project/ptm_data/wiki/'\n",
      "\n",
      "#doclist_arxiv = {}\n",
      "# do a quick run through with lists, see what happens\n",
      "doclist_wiki_dict = {}\n",
      "doclist_wiki_list = []\n",
      "\n",
      "tfidf_check = pd.DataFrame() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# loop over all documents\n",
      "for subidr, dirs, files in os.walk(path_wiki):\n",
      "    for file in files:\n",
      "        file_path = path_wiki + file\n",
      "        shakes = open(file_path, 'r')\n",
      "        text = shakes.read()\n",
      "        lowers = text.lower()\n",
      "        no_punctuation = lowers.translate(None, string.punctuation)\n",
      "        \n",
      "        doclist_wiki_list.append( tb(no_punctuation) )\n",
      "        doclist_wiki_dict[file] = TextBlob(no_punctuation)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for doc in doclist_wiki_dict:\n",
      "    print(doc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "efficiency_(statistics).txt\n",
        "convergence_of_random_variables.txt\n",
        "consistency_(statistics).txt\n",
        "completeness_(statistics).txt\n",
        "analytic_and_enumerative_statistical_studies.txt\n",
        "random_variable.txt\n",
        "statistical_inference.txt\n",
        "design_of_experiments.txt\n",
        "maximum_likelihood.txt\n",
        "consistent_estimator.txt\n",
        "window_function.txt\n",
        "parameter_space.txt\n",
        "entropy_(information_theory).txt\n",
        "youden's_j_statistic.txt\n",
        "studentization.txt\n",
        "fisher_consistency.txt\n",
        "pivotal_quantity.txt\n",
        "recursive_partitioning.txt\n",
        "independent_and_identically_distributed_random_variables.txt\n",
        "frequency_(statistics).txt\n",
        "maximum_a_posteriori_estimation.txt\n",
        "fiducial_inference.txt\n",
        "statistical_manifold.txt\n",
        "kullback\u00e2\u0080\u0093leibler_divergence.txt\n",
        "bayesian_inference.txt\n",
        "sufficient_statistic.txt\n",
        "efficient_estimator.txt\n",
        "spatial_dependence.txt\n",
        "winsorising.txt\n",
        "peirce's_criterion.txt\n",
        "sensitivity_and_specificity.txt\n",
        "restricted_maximum_likelihood.txt\n",
        "exponential_dispersion_model.txt\n",
        "behrens\u00e2\u0080\u0093fisher_problem.txt\n",
        "nuisance_parameter.txt\n",
        "loss_function.txt\n",
        "asymptotic_theory_(statistics).txt\n",
        "statistical_parameter.txt\n",
        "conditionality_principle.txt\n",
        "statistical_model.txt\n",
        "information_geometry.txt\n",
        "extreme_value_theory.txt\n",
        "magnitude_of_completeness.txt\n",
        "response_surface_methodology.txt\n",
        "edgeworth_series.txt\n",
        "model_selection.txt\n",
        "decoupling_(probability).txt\n",
        "statistic.txt\n",
        "bias_of_an_estimator.txt\n",
        "a_priori_probability.txt\n",
        "uncertainty.txt\n",
        "ancillary_statistic.txt\n",
        "errors_and_residuals.txt\n",
        "parametric_model.txt\n",
        "coherence_(statistics).txt\n",
        "likelihood-ratio_test.txt\n",
        "berkson_error_model.txt\n",
        "statistical_population.txt\n",
        "semiparametric_model.txt\n",
        "mathematical_statistics.txt\n",
        "principle_of_maximum_entropy.txt\n",
        "binomial_proportion_confidence_interval.txt\n",
        "statistical_assumption.txt\n",
        "invariant_estimator.txt\n",
        "sampling_distribution.txt\n",
        "l-statistic.txt\n",
        "bias_(statistics).txt\n",
        "robust_statistics.txt\n",
        "shrinkage_(statistics).txt\n",
        "fisher_transformation.txt\n",
        "optimal_design.txt\n",
        "shrinkage_estimator.txt\n",
        "galton's_problem.txt\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, doc in enumerate(doclist_wiki_dict):\n",
      "    ## lists implementation\n",
      "    #print(\"Top words in document {}\".format(i+1))\n",
      "    #scores = {word: tfidf(word, doc, doclist_wiki) for word in doc.words}\n",
      "    #sorted_words = sorted(scores.items(), key=lambda x : x[1], reverse = True)\n",
      "    #for word, score in sorted_words[:5]:\n",
      "        #print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))\n",
      "    \n",
      "    #dictionary implementation\n",
      "    print(\"Top words in document: {}\".format(doc))\n",
      "    scores = {word: tfidf_dict(word, doclist_wiki_dict[doc], doclist_wiki_dict) for word in doclist_wiki_dict[doc].words}\n",
      "    sorted_words = sorted(scores.items(), key=lambda x : x[1], reverse = True)\n",
      "    for word, score in sorted_words[:5]:\n",
      "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top words in document: efficiency_(statistics).txt\n",
        "\tWord: efficiency, TF-IDF: 0.0617"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: estimator, TF-IDF: 0.01456\n",
        "\tWord: estimators, TF-IDF: 0.01453\n",
        "\tWord: efficient, TF-IDF: 0.01348\n",
        "\tWord: relative, TF-IDF: 0.01342\n",
        "Top words in document: convergence_of_random_variables.txt\n",
        "\tWord: convergence, TF-IDF: 0.07618"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: converges, TF-IDF: 0.0365\n",
        "\tWord: xn, TF-IDF: 0.03067\n",
        "\tWord: almost, TF-IDF: 0.0174\n",
        "\tWord: surely, TF-IDF: 0.01421\n",
        "Top words in document: consistency_(statistics).txt\n",
        "\tWord: records, TF-IDF: 0.03423"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: items, TF-IDF: 0.02806\n",
        "\tWord: increases, TF-IDF: 0.02537\n",
        "\tWord: consistency, TF-IDF: 0.0242\n",
        "\tWord: sites, TF-IDF: 0.01929\n",
        "Top words in document: completeness_(statistics).txt\n",
        "\tWord: completeness, TF-IDF: 0.01663"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: complete, TF-IDF: 0.0162\n",
        "\tWord: sufficient, TF-IDF: 0.01578\n",
        "\tWord: boundedly, TF-IDF: 0.01276\n",
        "\tWord: minimal, TF-IDF: 0.01045\n",
        "Top words in document: analytic_and_enumerative_statistical_studies.txt\n",
        "\tWord: enumerative, TF-IDF: 0.10251"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: analytic, TF-IDF: 0.06681\n",
        "\tWord: study, TF-IDF: 0.0369\n",
        "\tWord: deming, TF-IDF: 0.02796\n",
        "\tWord: studies, TF-IDF: 0.02682\n",
        "Top words in document: random_variable.txt\n",
        "\tWord: random, TF-IDF: 0.01767"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-51-aa99cc3930bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#dictionary implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Top words in document: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtfidf_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoclist_wiki_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoclist_wiki_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoclist_wiki_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0msorted_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-51-aa99cc3930bf>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m((word,))\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#dictionary implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Top words in document: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtfidf_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoclist_wiki_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoclist_wiki_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoclist_wiki_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0msorted_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-48-7a7bc7b297c1>\u001b[0m in \u001b[0;36mtfidf_dict\u001b[0;34m(word, blob, bloblist)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtfidf_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0midf_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-48-7a7bc7b297c1>\u001b[0m in \u001b[0;36midf_dict\u001b[0;34m(word, bloblist)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0midf_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_containing_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtfidf_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-48-7a7bc7b297c1>\u001b[0m in \u001b[0;36mn_containing_dict\u001b[0;34m(word, bloblist_dict)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mn_containing_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbloblist_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbloblist_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0midf_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-48-7a7bc7b297c1>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((blob,))\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mn_containing_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbloblist_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbloblist_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0midf_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloblist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/textblob/mixins.pyc\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, sub)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;34m'''Implements the `in` keyword like a Python string.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tWord: realvalued, TF-IDF: 0.0111\n",
        "\tWord: space, TF-IDF: 0.00811\n",
        "\tWord: measurable, TF-IDF: 0.00748\n",
        "\tWord: variables, TF-IDF: 0.00688\n",
        "Top words in document: statistical_inference.txt\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So my highest scoring TF-IDF words are 'the' and 'of'. Something is not going correctly here. Tomorrow (or sometime later) I will take a single document and print out all the words and their TF-IDF scores. \n",
      "\n",
      "**NOTE** When using list implementation fo doclist, it works. Something about the dictionary messes things up. But, I want to keep the dictionary implementation so that I can attach the names of the wiki concepts to the documents."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}