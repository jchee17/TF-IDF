{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division, unicode_literals\n",
      "\n",
      "import os\n",
      "import re\n",
      "import webbrowser\n",
      "import random\n",
      "import pickle\n",
      "import string\n",
      "import nltk\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import math\n",
      "from textblob import TextBlob\n",
      "\n",
      "path_arxiv = '/home/jerry/Data/Hopper_Project/ptm_data/arxiv_processed_trunc/'\n",
      "path_wiki = '/home/jerry/Data/Hopper_Project/ptm_data/wiki/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load the document comparisons\n",
      "doc_comparisons = pickle.load(open('./doc_comparisons.p', 'r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# function to take in a arxiv paper name and output the top k wiki concepts\n",
      "\n",
      "def relevant_concepts(arxiv_doc, doc_comparisons, k):\n",
      "    print(\"\\nTop words in document: {}\".format(arxiv_doc))\n",
      "    \n",
      "    # check if arxiv_doc in doc_comparsions\n",
      "    if arxiv_doc in doc_comparisons.keys(): \n",
      "        scores = doc_comparisons[arxiv_doc]\n",
      "        sorted_words = sorted(scores.items(), key=lambda x : x[1], reverse = True)\n",
      "        for concept, score in sorted_words[:k]:\n",
      "            print(\"\\tConcept: {}, TF-IDF: {}\".format(concept, round(score, 5)))\n",
      "    \n",
      "    else:\n",
      "        print(\"\\tError: input doc not in doc_comparisons\")\n",
      "        \n",
      "def show_doc_text(arxiv_doc):\n",
      "    f = open('/home/jerry/Data/Hopper_Project/ptm_data/arxiv_processed_trunc/' + arxiv_doc, 'r')\n",
      "    text = f.read()\n",
      "    f.close()\n",
      "    print('\\n' + 'Title: ' + arxiv_doc + '\\n\\n' + text)\n",
      "    \n",
      "def show_doc_pdf(arxiv_doc):\n",
      "    # first get the article id from string input\n",
      "    id_string = re.sub('\\_trunc.txt', '', arxiv_doc)\n",
      "    webbrowser.open('http://arxiv.org/pdf/' + id_string + '.pdf')\n",
      "    \n",
      "def search_concept(query, k):\n",
      "    # first get a list of wiki concepts\n",
      "    articles = doc_comparisons.keys()\n",
      "    wiki_concepts = doc_comparisons[articles[0]].keys()\n",
      "    \n",
      "    # check if query in wiki_concepts\n",
      "    if query not in wiki_concepts:\n",
      "        print(\"Query not in wiki_concepts, please try again. These are the searchable concepts\\n\")\n",
      "        print(wiki_concepts)\n",
      "    else:\n",
      "        scores = {article: doc_comparisons[article][query] \n",
      "                  for article in articles}\n",
      "        sorted_scores = sorted(scores.items(), key=lambda x : x[1], reverse = True)\n",
      "        print(\"Wiki Concept: {}\\n\".format(query))\n",
      "        for article, score in sorted_scores[:k]:\n",
      "            print(\"\\tArticle: {}, TF-IDF: {}\".format(article, round(score, 5)))\n",
      "        \n",
      "def article_comparison(article1, article2, doc_comparisons):\n",
      "    # compares two articles in doc_comparisons \n",
      "    # based on the cosine distance of their tf-idf \n",
      "    # wiki vectors\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wiki_concepts = doc_comparisons[articles[0]].keys()\n",
      "\n",
      "search_concept(wiki_concepts[0], 5)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Wiki Concept: efficiency_(statistics).txt\n",
        "\n",
        "\tArticle: 1401.2272_trunc.txt, TF-IDF: 0.23241\n",
        "\tArticle: 1405.7210_trunc.txt, TF-IDF: 0.21904\n",
        "\tArticle: 1208.0687_trunc.txt, TF-IDF: 0.18873\n",
        "\tArticle: 1501.00312_trunc.txt, TF-IDF: 0.18716\n",
        "\tArticle: 1403.2954_trunc.txt, TF-IDF: 0.17839\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "articles = doc_comparisons.keys()\n",
      "indices = list(xrange(len(articles)))\n",
      "\n",
      "while(1):\n",
      "    i = raw_input(\"There are 596 analyzed arxiv articles. Enter an integer from 0 to {} to access one of these articles.\\n\".format(len(articles)-1))\n",
      "    i = int(i)\n",
      "    if i not in indices:\n",
      "        print(\"Input not in range. Please try again.\\n\")\n",
      "    else:\n",
      "        relevant_concepts(articles[i], doc_comparisons, 5)\n",
      "        show_doc_pdf(articles[i])\n",
      "        print('\\n')\n",
      "        #show_doc_text(articles[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "There are 596 analyzed arxiv articles. Enter an integer from 0 to 595 to access one of these articles.\n",
        "0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Top words in document: 1103.5679_trunc.txt\n",
        "\tConcept: consistent_estimator.txt, TF-IDF: 0.19094\n",
        "\tConcept: convergence_of_random_variables.txt, TF-IDF: 0.17523\n",
        "\tConcept: consistency_(statistics).txt, TF-IDF: 0.16065\n",
        "\tConcept: asymptotic_theory_(statistics).txt, TF-IDF: 0.16033\n",
        "\tConcept: fisher_consistency.txt, TF-IDF: 0.14355\n",
        "\n",
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-8-56a62a7dc096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"There are 596 analyzed arxiv articles. Enter an integer from 0 to {} to access one of these articles.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/IPython/kernel/zmq/ipkernel.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;31m# raw_input in the user namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0mraw_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/IPython/kernel/zmq/ipkernel.pyc\u001b[0m in \u001b[0;36m_raw_input\u001b[0;34m(self, prompt, ident, parent)\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc_comparisons[articles[0]].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[u'efficiency_(statistics).txt',\n",
        " u'convergence_of_random_variables.txt',\n",
        " u'consistency_(statistics).txt',\n",
        " u'completeness_(statistics).txt',\n",
        " u'analytic_and_enumerative_statistical_studies.txt',\n",
        " u'random_variable.txt',\n",
        " u'statistical_inference.txt',\n",
        " u'design_of_experiments.txt',\n",
        " u'maximum_likelihood.txt',\n",
        " u'consistent_estimator.txt',\n",
        " u'parameter_space.txt',\n",
        " u\"youden's_j_statistic.txt\",\n",
        " u'studentization.txt',\n",
        " u'fisher_consistency.txt',\n",
        " u'pivotal_quantity.txt',\n",
        " u'nuisance_parameter.txt',\n",
        " u'window_function.txt',\n",
        " u'optimal_design.txt',\n",
        " u'fiducial_inference.txt',\n",
        " u'statistical_manifold.txt',\n",
        " u'kullback\\xe2\\x80\\x93leibler_divergence.txt',\n",
        " u'bayesian_inference.txt',\n",
        " u'sufficient_statistic.txt',\n",
        " u'efficient_estimator.txt',\n",
        " u'maximum_a_posteriori_estimation.txt',\n",
        " u'winsorising.txt',\n",
        " u\"peirce's_criterion.txt\",\n",
        " u'recursive_partitioning.txt',\n",
        " u'restricted_maximum_likelihood.txt',\n",
        " u'a_priori_probability.txt',\n",
        " u'behrens\\xe2\\x80\\x93fisher_problem.txt',\n",
        " u'exponential_dispersion_model.txt',\n",
        " u'loss_function.txt',\n",
        " u'magnitude_of_completeness.txt',\n",
        " u'sensitivity_and_specificity.txt',\n",
        " u'spatial_dependence.txt',\n",
        " u'statistical_parameter.txt',\n",
        " u'conditionality_principle.txt',\n",
        " u'statistical_model.txt',\n",
        " u'information_geometry.txt',\n",
        " u'extreme_value_theory.txt',\n",
        " u'asymptotic_theory_(statistics).txt',\n",
        " u'response_surface_methodology.txt',\n",
        " u'edgeworth_series.txt',\n",
        " u'decoupling_(probability).txt',\n",
        " u'principle_of_maximum_entropy.txt',\n",
        " u'shrinkage_(statistics).txt',\n",
        " u'bias_of_an_estimator.txt',\n",
        " u'entropy_(information_theory).txt',\n",
        " u'uncertainty.txt',\n",
        " u'ancillary_statistic.txt',\n",
        " u'errors_and_residuals.txt',\n",
        " u'parametric_model.txt',\n",
        " u'coherence_(statistics).txt',\n",
        " u'likelihood-ratio_test.txt',\n",
        " u'berkson_error_model.txt',\n",
        " u'model_selection.txt',\n",
        " u'semiparametric_model.txt',\n",
        " u'mathematical_statistics.txt',\n",
        " u'frequency_(statistics).txt',\n",
        " u'binomial_proportion_confidence_interval.txt',\n",
        " u'statistical_assumption.txt',\n",
        " u'invariant_estimator.txt',\n",
        " u'sampling_distribution.txt',\n",
        " u'l-statistic.txt',\n",
        " u'bias_(statistics).txt',\n",
        " u'statistical_population.txt',\n",
        " u'robust_statistics.txt',\n",
        " u'statistic.txt',\n",
        " u'fisher_transformation.txt',\n",
        " u'independent_and_identically_distributed_random_variables.txt',\n",
        " u'shrinkage_estimator.txt',\n",
        " u\"galton's_problem.txt\"]"
       ]
      }
     ],
     "prompt_number": 10
    }
   ],
   "metadata": {}
  }
 ]
}