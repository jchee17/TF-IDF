{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "from __future__ import unicode_literals\n",
      "from __future__ import division\n",
      "\n",
      "import os\n",
      "import re\n",
      "import timeit\n",
      "import math\n",
      "import codecs\n",
      "import string\n",
      "import pickle\n",
      "import csv\n",
      "from numpy import linalg as LA\n",
      "import numpy as np\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "from nltk.tokenize\n",
      "from scipy import spatial"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def concept_list_csv_(concept_fname, path_concepts):\n",
      "    \"\"\" reads in a csv file, \n",
      "        outputs as python list in given path\n",
      "        as pickled object. unicode.\n",
      "        Also add unigrams for every line\"\"\"\n",
      "    # open file pointer\n",
      "    f = codecs.open(path_concepts+concept_fname, 'r', \"utf-8\")\n",
      "    \n",
      "    # output list\n",
      "    concepts = []\n",
      "    \n",
      "    # read in lines\n",
      "    for line in f.readlines():\n",
      "        concepts = concepts + ine.lower().strip(\"\\n\").split(',')\n",
      "\n",
      "    # from observation the concept lists all had ''\n",
      "    while ('' in concepts):\n",
      "        concepts.remove('')\n",
      "\n",
      "    return concepts\n",
      "    # pickle \n",
      "    #pickle.dump(concepts, open(path_save+save_fname, 'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def add_unigrams(list_concepts):\n",
      "    \"\"\" add unigrams to concepts. note does not\n",
      "    preserve order\"\"\"\n",
      "    unigrams = set()\n",
      "    set_concepts = set(list_concepts)\n",
      "    tokenizer = RegexpTokenizer(ur'\\w+')\n",
      "    \n",
      "    for phrase in list_concepts:\n",
      "        unigrams.update(tokenizer.tokenize(phrase))\n",
      "    \n",
      "    set_concepts.update(unigrams)\n",
      "    \n",
      "    return list(set_concepts)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def concept_title_csv(concept_fname, path_concepts):\n",
      "    \"\"\" reads in csv file,\n",
      "        outputs as python list in given path\n",
      "        as pickled object. unicode. \n",
      "        takes first word on each line \"\"\"\n",
      "    # open file pointer\n",
      "    f = codecs.open(path_concepts+concept_fname, 'r', \"utf-8\")\n",
      "    \n",
      "    # output list\n",
      "    titles = []\n",
      "    page = []\n",
      "    \n",
      "    # read in lines, take 1st word of each line\n",
      "    for line in f.readlines():\n",
      "        page = line.lower().strip(\"\\n\").split(',')\n",
      "        titles.append(page[0])\n",
      "\n",
      "    # from observation the concept lists all had ''\n",
      "    while ('' in titles):\n",
      "        titles.remove('')\n",
      "        \n",
      "    return titles\n",
      "    # pickle \n",
      "    #pickle.dump(concepts, open(path_save+save_fname, 'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "concepts_txt = \"phrases-bold\"\n",
      "path_concepts_txt = \"./data_objects/\"\n",
      "path_save = \"./data_objects/\"\n",
      "concepts_pickle = \"phrases-bold.p\"\n",
      "\n",
      "concepts = concept_list_csv(concepts_txt, path_concepts_txt)\n",
      "vocab = add_unigrams(concepts)\n",
      "titles = concept_title_csv(concepts_txt, path_concepts_txt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(concepts, open(\"./data_objects/concepts.p\", 'w'))\n",
      "pickle.dump(vocab, open(\"./data_objects/vocab.p\", 'w'))\n",
      "pickle.dump(titles, open(\"./data_objects/titles.p\", 'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    }
   ],
   "metadata": {}
  }
 ]
}